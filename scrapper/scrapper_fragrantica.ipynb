{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import undetected_chromedriver as uc\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST CELL - Version 1 - scrap anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # Run without opening a browser\n",
    "# options.add_argument(\"start-maximized\")\n",
    "# options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Reduce bot detection\n",
    "# options.add_argument(\"user-agent=Mozilla/5.0\")  # Mimic a real browser\n",
    "\n",
    "# # Initialize the driver\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# # Open the website\n",
    "# URL = \"https://www.fragrantica.com/search/\"  # Replace with the actual page containing the perfumes\n",
    "# driver.get(URL)\n",
    "\n",
    "# # Allow time for JavaScript to load\n",
    "# driver.implicitly_wait(3)\n",
    "\n",
    "# # Extract elements by class name\n",
    "# items = driver.find_elements(By.CLASS_NAME, \"cell.card.fr-news-box\")\n",
    "\n",
    "# # Print perfume names (if they have a sub-element with text)\n",
    "# for item in items:\n",
    "#     print(item.text)\n",
    "#     link = item.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "#     print(link)\n",
    "#     print('\\n')\n",
    "    \n",
    "# # Close driver\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST CELL - Version 2 - scrap perfume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find accords\n",
    "def find_accords(driver):\n",
    "    accord_list = []\n",
    "    accords = driver.find_elements(By.CLASS_NAME, \"accord-bar\")\n",
    "    for accord in accords:\n",
    "        style_attribute = accord.get_attribute(\"style\")\n",
    "        match = re.search(r'width:\\s*([\\d.]+%)', style_attribute)\n",
    "        width_value = match.group(1) if match else \"N/A\"\n",
    "        accord_list.append((accord.text, width_value))\n",
    "    return accord_list\n",
    "    \n",
    "# Find description   \n",
    "def find_description(driver):\n",
    "    return driver.find_element(By.XPATH,\"//div[contains(@itemprop, 'description')]\").text\n",
    "\n",
    "# Find pros and cons\n",
    "def find_pros_and_cons(driver):\n",
    "    pros_and_cons = []\n",
    "    try:\n",
    "        pros = driver.find_elements(By.CLASS_NAME, \"cell.small-12\")\n",
    "        for pro in pros:\n",
    "            style = pro.get_attribute(\"style\")  # Get the style attribute\n",
    "            if \"display: inline-flex;\" in style and \"margin: 0.4rem;\" in style and \"overflow-wrap: break-word;\" in style and \"padding: 0px 0.6rem;\" in style:\n",
    "                spans = pro.find_elements(By.TAG_NAME, \"span\")  # Get all <span> elements inside the div\n",
    "                if spans:\n",
    "                    last_span_text = spans[-1].get_attribute(\"textContent\")  # Get the last span\n",
    "                    pros_and_cons.append(last_span_text)\n",
    "        return pros_and_cons\n",
    "    except:\n",
    "        return None\n",
    "            \n",
    "# Find notes\n",
    "def find_notes(driver):\n",
    "    pyramid_element = driver.find_element(By.XPATH, '//*[@id=\"pyramid\" and contains(@class, \"grid-x\") and contains(@class, \"grid-padding-y\")]')\n",
    "    ingredients_html = pyramid_element.get_attribute('outerHTML')\n",
    "    soup = BeautifulSoup(ingredients_html, 'html.parser')\n",
    "\n",
    "    # Initialize the three lists\n",
    "    top_notes = []\n",
    "    middle_notes = []\n",
    "    base_notes = []\n",
    "\n",
    "    # Find all h4 tags that contain the note categories\n",
    "    h4_tags = soup.find_all('h4')\n",
    "    if h4_tags:\n",
    "        for h4 in h4_tags:\n",
    "            if 'Top Notes' in h4.text:\n",
    "                notes_div = h4.find_next_sibling('div')\n",
    "                top_notes = [div.text.strip() for div in notes_div.find_all('div') \n",
    "                            if div.find('a') and not div.find('img')]\n",
    "            elif 'Middle Notes' in h4.text:\n",
    "                notes_div = h4.find_next_sibling('div')\n",
    "                middle_notes = [div.text.strip() for div in notes_div.find_all('div') \n",
    "                            if div.find('a') and not div.find('img')]\n",
    "            elif 'Base Notes' in h4.text:\n",
    "                notes_div = h4.find_next_sibling('div')\n",
    "                base_notes = [div.text.strip() for div in notes_div.find_all('div') \n",
    "                            if div.find('a') and not div.find('img')]\n",
    "    else:\n",
    "        note_divs = soup.find_all('div', style=lambda value: value and 'margin: 0.2rem; display: flex; justify-content: center; flex-direction: column; text-align: center' in value)\n",
    "        top_notes = [div.find('div').find_next_sibling('div').get_text(strip=True) for div in note_divs]\n",
    "\n",
    "    return top_notes, middle_notes, base_notes\n",
    "\n",
    "def find_gender(driver):\n",
    "    gender = driver.find_element(By.XPATH,\"//div[contains(@id, 'toptop')]\").text.split('for ')[2]\n",
    "    return gender\n",
    "\n",
    "def find_longevity(driver):\n",
    "    longevity = driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")[4].text\n",
    "    lines = longevity.split('\\n')[2:]\n",
    "    result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "    return result\n",
    "\n",
    "def find_sillage(driver):\n",
    "    # all_elements= driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")\n",
    "    # sillage = all_elements[5].text\n",
    "    # lines = sillage.split('\\n')[2:]\n",
    "    # result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "    sillage = driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")[5].text\n",
    "    lines = sillage.split('\\n')[2:]\n",
    "    result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "    return result\n",
    "    \n",
    "def find_price(driver):\n",
    "    price = driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")[7].text\n",
    "    lines = price.split('\\n')[2:]\n",
    "    result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "    return result\n",
    "\n",
    "# Call all scrapping functions\n",
    "def scrap_perfume(driver, url):\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    # print(find_accords(driver))\n",
    "    # print(find_description(driver))\n",
    "    # print(find_pros_and_cons(driver))\n",
    "    print(find_notes(driver))\n",
    "    # print(find_gender(driver))\n",
    "    # print(find_longevity(driver))\n",
    "    # print(find_price(driver))\n",
    "    \n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # Run without opening a browser\n",
    "# options.add_argument(\"start-maximized\")\n",
    "# options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Reduce bot detection\n",
    "# options.add_argument(\"user-agent=Mozilla/5.0\")  # Mimic a real browser\n",
    "\n",
    "# # Initialize the driver\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# scrap_perfume(driver, 'https://www.fragrantica.com/perfume/Lattafa-Perfumes/Khamrah-75805.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Croissant', 'Sandalwood', 'Vanilla', 'Tonka Bean', 'Wild Berries', 'Black Currant'], [], [])\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run without opening a browser\n",
    "options.add_argument(\"start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Reduce bot detection\n",
    "options.add_argument(\"user-agent=Mozilla/5.0\")  # Mimic a real browser\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "scrap_perfume(driver, 'https://www.fragrantica.com/perfume/The-Dua-Brand/Couture-Crumbled-93882.html')\n",
    "# driver.implicitly_wait(5)\n",
    "\n",
    "# price = driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")[7].text\n",
    "# lines = price.split('\\n')[2:]\n",
    "# result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "# print(result)\n",
    "\n",
    "# price = driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")\n",
    "# for index, element in enumerate(price):\n",
    "#     print(index, element.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING CODE !!! Version 3 - class to scrap list and perfume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Driver:\n",
    "    def __init__(self):\n",
    "        self.options = uc.ChromeOptions()\n",
    "        self.options.headless = False  # Keep headless mode OFF to avoid detection\n",
    "        self.options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        self.options.add_argument(\"user-agent=Mozilla/5.0\")  # Custom user agent\n",
    "\n",
    "        self.driver = uc.Chrome(options=self.options)\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "        \n",
    "    def scrap_list(self, url, how_many_reloads):\n",
    "        self.driver.get(url)\n",
    "        self.click_show_more(how_many_reloads)\n",
    "        perfumes_list = []\n",
    "        perfumes = self.wait.until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"cell.card.fr-news-box\"))\n",
    "        )\n",
    "        \n",
    "        for perfume in perfumes:\n",
    "            try:\n",
    "                link = self.wait.until(\n",
    "                    lambda d: perfume.find_element(By.TAG_NAME, \"a\")\n",
    "                ).get_attribute(\"href\")\n",
    "                name = perfume.text.split('\\n')\n",
    "                perfumes_list.append((name, link))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing perfume: {e}\")\n",
    "                continue\n",
    "                \n",
    "        return perfumes_list\n",
    "    \n",
    "    def find_gender(self):\n",
    "        try:\n",
    "            gender_text = self.wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[contains(@id, 'toptop')]\"))\n",
    "            ).text\n",
    "            return gender_text.split('for ')[1] if 'for ' in gender_text else \"Unknown\"\n",
    "        except:\n",
    "            return \"Unknown\"\n",
    "    \n",
    "    def find_accords(self):\n",
    "        accord_list = []\n",
    "        try:\n",
    "            accords = self.wait.until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, \"accord-bar\"))\n",
    "            )\n",
    "            for accord in accords:\n",
    "                style_attribute = accord.get_attribute(\"style\")\n",
    "                match = re.search(r'width:\\s*([\\d.]+%)', style_attribute)\n",
    "                width_value = match.group(1) if match else \"N/A\"\n",
    "                accord_list.append((accord.text, width_value))\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding accords: {e}\")\n",
    "        return accord_list\n",
    "        \n",
    "    def find_description(self):\n",
    "        try:\n",
    "            description = self.wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[@itemprop='description']\"))\n",
    "            )\n",
    "            try: \n",
    "                description = description.text.replace(\"\\n\", \"\")\n",
    "                return description\n",
    "            except:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding description: {e}\")\n",
    "            return None\n",
    "\n",
    "    def find_pros_and_cons(self):\n",
    "        pros_and_cons = []\n",
    "        try:\n",
    "            pros = self.wait.until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, \"cell.small-12\"))\n",
    "            )\n",
    "            for pro in pros:\n",
    "                try:\n",
    "                    style = pro.get_attribute(\"style\") or \"\"\n",
    "                    if all(x in style for x in [\"display: inline-flex;\", \"margin: 0.4rem;\", \n",
    "                                              \"overflow-wrap: break-word;\", \"padding: 0px 0.6rem;\"]):\n",
    "                        spans = pro.find_elements(By.TAG_NAME, \"span\")\n",
    "                        if spans:\n",
    "                            last_span_text = spans[-1].get_attribute(\"textContent\")\n",
    "                            pros_and_cons.append(last_span_text.strip())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing pro/con: {e}\")\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding pros/cons: {e}\")\n",
    "        return pros_and_cons if pros_and_cons else None\n",
    "                \n",
    "    def find_notes(self):\n",
    "        try:\n",
    "            pyramid_element = self.wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"pyramid\"]'))\n",
    "            )\n",
    "            ingredients_html = pyramid_element.get_attribute('outerHTML')\n",
    "            soup = BeautifulSoup(ingredients_html, 'html.parser')\n",
    "\n",
    "            notes = {\"top\": [], \"middle\": [], \"base\": []}\n",
    "            \n",
    "            h4_notes = soup.find_all('h4')\n",
    "            if h4_notes:\n",
    "                for h4 in h4_notes:\n",
    "                    notes_div = h4.find_next_sibling('div')\n",
    "                    if not notes_div:\n",
    "                        continue\n",
    "                        \n",
    "                    note_divs = [div for div in notes_div.find_all('div') \n",
    "                                if div.find('a') and not div.find('img')]\n",
    "                    note_names = [div.get_text(strip=True) for div in note_divs]\n",
    "                    \n",
    "                    if 'Top Notes' in h4.text:\n",
    "                        notes[\"top\"] = note_names\n",
    "                    elif 'Middle Notes' in h4.text:\n",
    "                        notes[\"middle\"] = note_names\n",
    "                    elif 'Base Notes' in h4.text:\n",
    "                        notes[\"base\"] = note_names                        \n",
    "            else:\n",
    "                note_divs = soup.find_all('div', style=lambda value: value and 'margin: 0.2rem; display: flex; justify-content: center; flex-direction: column; text-align: center' in value)\n",
    "                notes[\"top\"] = [div.find('div').find_next_sibling('div').get_text(strip=True) for div in note_divs]\n",
    "\n",
    "            return notes[\"top\"], notes[\"middle\"], notes[\"base\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding notes: {e}\")\n",
    "            return [], [], []\n",
    "        \n",
    "    def find_longevity(self):\n",
    "        try:\n",
    "            longevity = self.driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")\n",
    "            longevity = longevity[4].text\n",
    "            # print(self.driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\").get_attribute('outerHTML'))\n",
    "            lines = longevity.split('\\n')[2:]\n",
    "            result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "            return result\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def find_sillage(self):\n",
    "        # all_elements= driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")\n",
    "        # sillage = all_elements[5].text\n",
    "        # lines = sillage.split('\\n')[2:]\n",
    "        # result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "        try:\n",
    "            sillage = self.driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")\n",
    "            sillage = sillage[5].text\n",
    "            lines = sillage.split('\\n')[2:]\n",
    "            result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "            return result\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def find_price(self):\n",
    "        try:\n",
    "            price = self.driver.find_elements(By.CLASS_NAME, \"cell.small-12.medium-6\")\n",
    "            price = price[7].text\n",
    "            lines = price.split('\\n')[2:]\n",
    "            result = \"; \".join(f\"{lines[i]}: {lines[i+1]}\" for i in range(0, len(lines), 2))\n",
    "            return result\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def scrap_perfume(self, url):\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))  # Wait for the full page to load\n",
    "\n",
    "            print(\"Scraping:\", url)  # Check if URL is accessed\n",
    "            print(\"Page title:\", self.driver.title)  # Check if page loaded\n",
    "\n",
    "            gender = self.find_gender()\n",
    "            accords = self.find_accords()\n",
    "            description = self.find_description()\n",
    "            pros_and_cons = self.find_pros_and_cons()\n",
    "            notes = self.find_notes()\n",
    "            longevity = self.find_longevity()\n",
    "            sillage = self.find_sillage()\n",
    "            price = self.find_price()\n",
    "\n",
    "            return {\n",
    "                'gender': gender,\n",
    "                'accords': accords,\n",
    "                'description': description,\n",
    "                'pros_and_cons': pros_and_cons,\n",
    "                'notes': notes,\n",
    "                'longevity': longevity,\n",
    "                'sillage': sillage,\n",
    "                'price': price,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping perfume {url}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def click_show_more(self, how_many_reloads):\n",
    "        for _ in range(how_many_reloads):\n",
    "            try:\n",
    "                # Find the button\n",
    "                button = self.wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Show more results')]\")))\n",
    "                button.click()  # Click it\n",
    "                print(\"Clicked 'Show more results' button\")\n",
    "                \n",
    "                # Wait for new content to load\n",
    "                self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"grid-x\")))  \n",
    "            except:\n",
    "                print(\"No more 'Show more results' button found\")\n",
    "                continue  # Stop when button is gone\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'driver'):\n",
    "            try:\n",
    "                self.driver.quit()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN CODE FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more 'Show more results' button found\n",
      "No more 'Show more results' button found\n",
      "No more 'Show more results' button found\n",
      "No more 'Show more results' button found\n",
      "No more 'Show more results' button found\n"
     ]
    }
   ],
   "source": [
    "driver = Driver()\n",
    "\n",
    "### CHANGE ONLY THESE ARGUMENTS\n",
    "\n",
    "# First argument - URL with perfumes list, Second argument - how many clicks to show more perfumes (each click is around 30 more perfumes loaded to the url, \n",
    "# but the request will be full after 50 unique perfumes scrapped)  \n",
    "perfume_list = driver.scrap_list(\"https://www.fragrantica.com/search/?dizajner=Versace\", 10)\n",
    "# perfume_list = perfume_list[64:]  ### CUT LIST OF PERFUMES IF ALREADY ARE SCRAPPED\n",
    "\n",
    "### \n",
    "\n",
    "for perfume in perfume_list: # Iterate through every perfume\n",
    "    try:\n",
    "        perfume_data = driver.scrap_perfume(perfume[1]) # Scrap new URL\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        try: # Sometimes name and producer is not retrieved from request \n",
    "            name = perfume[0][0]\n",
    "            producer = perfume[0][1]\n",
    "        except:\n",
    "            name = perfume[0][0]\n",
    "            producer = '' \n",
    "        try:\n",
    "            row = [\n",
    "                name, # Name\n",
    "                producer, # Producer,\n",
    "                perfume[1], # URL\n",
    "                perfume_data['gender'], # Gender\n",
    "                \"; \".join([f\"{accord[0]} ({accord[1]})\" for accord in perfume_data['accords']]),  # Accords\n",
    "                perfume_data['description'],\n",
    "                perfume_data['pros_and_cons'],  # Using \" | \" as a separator for better readability\n",
    "                perfume_data['notes'][0],  # Top notes (comma-separated)\n",
    "                perfume_data['notes'][1],  # Middle notes\n",
    "                perfume_data['notes'][2],   # Base notes\n",
    "                perfume_data['longevity'],\n",
    "                perfume_data['sillage'],\n",
    "                perfume_data['price'],\n",
    "            ]\n",
    "        except:\n",
    "            continue\n",
    "        with open('fragrance_data.csv', 'a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
